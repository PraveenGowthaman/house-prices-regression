{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b43374a",
   "metadata": {},
   "source": [
    "# House Prices: End-to-End Regression Pipeline\n",
    "\n",
    "This notebook presents a complete machine learning workflow for predicting\n",
    "residential property sale prices using structured tabular data.\n",
    "\n",
    "The solution covers exploratory data analysis, preprocessing, feature engineering,\n",
    "modeling, evaluation, and ensembling using scikit-learn pipelines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a87d98c",
   "metadata": {},
   "source": [
    "## 1. Problem Statement\n",
    "\n",
    "The objective is to predict the final sale price of residential homes based on a\n",
    "mix of numerical and categorical features describing their properties.\n",
    "\n",
    "This is a supervised regression problem evaluated using **Root Mean Squared Log Error (RMSLE)**,\n",
    "which penalizes relative prediction errors and motivates training in log-transformed space.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424ab62f",
   "metadata": {},
   "source": [
    "## 2. Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "id": "9bf52b92",
   "metadata": {},
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "54b5e44a",
   "metadata": {},
   "source": [
    "## 3. Data Loading\n",
    "\n",
    "The dataset consists of:\n",
    "- `train.csv`: training data with features and target (`SalePrice`)\n",
    "- `test.csv`: test data without target values\n",
    "\n",
    "The data is loaded from local files using relative paths to ensure portability.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "08e470b1",
   "metadata": {},
   "source": [
    "housing_train = pd.read_csv(\"house-prices-data/train.csv\")\n",
    "housing_test = pd.read_csv(\"house-prices-data/test.csv\")\n",
    "\n",
    "housing_train.shape, housing_test.shape\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5df6b68b",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis (EDA)\n",
    "\n",
    "Before modeling, we explore the dataset to understand:\n",
    "- The distribution of the target variable\n",
    "- Feature types (numerical vs categorical)\n",
    "- Presence of missing values\n",
    "- Key relationships between features and the target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285e678e",
   "metadata": {},
   "source": [
    "### 4.1 Dataset overview"
   ]
  },
  {
   "cell_type": "code",
   "id": "480c73d9",
   "metadata": {},
   "source": [
    "housing_train.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "74839667",
   "metadata": {},
   "source": [
    "### 4.2 Target distribution"
   ]
  },
  {
   "cell_type": "code",
   "id": "d506aacd",
   "metadata": {},
   "source": [
    "housing_train[\"SalePrice\"].describe()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d7b6453d",
   "metadata": {},
   "source": [
    "housing_train[\"SalePrice\"].hist(bins=50, figsize=(12, 6))\n",
    "plt.title(\"SalePrice Distribution\")\n",
    "plt.xlabel(\"SalePrice\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3a65a43d",
   "metadata": {},
   "source": [
    "### 4.3 Missing values (training set)"
   ]
  },
  {
   "cell_type": "code",
   "id": "9564c472",
   "metadata": {},
   "source": [
    "missing = housing_train.isnull().sum()\n",
    "missing[missing > 0].sort_values(ascending=False).head(30)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c36d1733",
   "metadata": {},
   "source": [
    "### 4.4 Feature relationship example\n",
    "\n",
    "We inspect relationships between important features (e.g., living area) and sale price\n",
    "to identify trends and potential outliers.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "724bbf5c",
   "metadata": {},
   "source": [
    "housing_train.plot(kind=\"scatter\", x=\"GrLivArea\", y=\"SalePrice\", grid=True, alpha=0.2)\n",
    "plt.title(\"GrLivArea vs SalePrice\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0b6b8f96",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering\n",
    "\n",
    "To incorporate domain knowledge and simplify learning, we add engineered features that capture\n",
    "important real-world relationships more directly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd69f0e",
   "metadata": {},
   "source": [
    "### 5.1 Engineered Features\n",
    "\n",
    "- `TotalSF`: total living area across basement + floors\n",
    "- `HouseAge`: age of the house at time of sale\n",
    "- `RemodAge`: years since last remodel\n",
    "- `HasGarage`: binary indicator for garage presence\n",
    "- `HasBasement`: binary indicator for basement presence\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "38ddfd0e",
   "metadata": {},
   "source": [
    "for df in [housing_train, housing_test]:\n",
    "    df[\"TotalSF\"] = df[\"TotalBsmtSF\"] + df[\"1stFlrSF\"] + df[\"2ndFlrSF\"]\n",
    "    df[\"HouseAge\"] = df[\"YrSold\"] - df[\"YearBuilt\"]\n",
    "    df[\"RemodAge\"] = df[\"YrSold\"] - df[\"YearRemodAdd\"]\n",
    "    # fillna(0) makes the boolean checks robust even before imputation\n",
    "    df[\"HasGarage\"] = (df[\"GarageCars\"].fillna(0) > 0).astype(int)\n",
    "    df[\"HasBasement\"] = (df[\"TotalBsmtSF\"].fillna(0) > 0).astype(int)\n",
    "\n",
    "housing_train[[\"TotalSF\",\"HouseAge\",\"RemodAge\",\"HasGarage\",\"HasBasement\"]].head()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6b3378cf",
   "metadata": {},
   "source": [
    "## 6. Preprocessing Pipeline\n",
    "\n",
    "We use scikit-learn Pipelines and `ColumnTransformer` to:\n",
    "- handle missing values without leakage\n",
    "- one-hot encode categorical variables\n",
    "- keep preprocessing consistent for training and inference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39803ba2",
   "metadata": {},
   "source": [
    "### 6.1 Split features and target\n",
    "\n",
    "We train in log space using `log1p(SalePrice)` to address target skew and align with RMSLE.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "d1059467",
   "metadata": {},
   "source": [
    "X = housing_train.drop(columns=[\"SalePrice\"])\n",
    "y = housing_train[\"SalePrice\"]\n",
    "y_log = np.log1p(y)\n",
    "\n",
    "X.shape, y.shape\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d0a30f27",
   "metadata": {},
   "source": [
    "### 6.2 Missing value strategy\n",
    "\n",
    "- Numerical columns where missing implies “not present” (garage/basement measures) → fill with 0  \n",
    "- Remaining numerical columns → fill with median  \n",
    "- Categorical columns → fill with \"None\" and one-hot encode\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "c774a443",
   "metadata": {},
   "source": [
    "zero_fill_num_cols = [\n",
    "    \"GarageYrBlt\", \"GarageArea\", \"GarageCars\",\n",
    "    \"BsmtFinSF1\", \"BsmtFinSF2\", \"BsmtUnfSF\", \"TotalBsmtSF\",\n",
    "]\n",
    "\n",
    "num_cols = X.select_dtypes(include=np.number).columns\n",
    "median_num_cols = [c for c in num_cols if c not in zero_fill_num_cols]\n",
    "cat_cols = X.select_dtypes(include=\"object\").columns\n",
    "\n",
    "numerical_median_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\"))\n",
    "])\n",
    "\n",
    "numerical_zero_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=0))\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"None\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num_zero\", numerical_zero_transformer, zero_fill_num_cols),\n",
    "        (\"num_median\", numerical_median_transformer, median_num_cols),\n",
    "        (\"cat\", categorical_transformer, cat_cols),\n",
    "    ]\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e20223f0",
   "metadata": {},
   "source": [
    "## 7. Models\n",
    "\n",
    "We train three different models (all wrapped in the same preprocessing pipeline):\n",
    "- Random Forest (non-linear bagging ensemble)\n",
    "- Gradient Boosting Regressor (boosting)\n",
    "- Ridge Regression (regularized linear baseline)\n",
    "\n",
    "Then we ensemble their predictions using a weighted average.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "9d156428",
   "metadata": {},
   "source": [
    "rf = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "gbr = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", GradientBoostingRegressor(\n",
    "        n_estimators=600,\n",
    "        learning_rate=0.03,\n",
    "        max_depth=3,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Note: Ridge doesn't need random_state; keep it simple and portable.\n",
    "ridge = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", Ridge(alpha=10.0))\n",
    "])\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f104b144",
   "metadata": {},
   "source": [
    "## 8. Evaluation\n",
    "\n",
    "We evaluate using RMSE in log space (`log1p(SalePrice)`).\n",
    "This is consistent with RMSLE-style evaluation and avoids accidentally double-logging the metric.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "73f79af4",
   "metadata": {},
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y_log, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "gbr.fit(X_train, y_train)\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "pred_rf = rf.predict(X_val)\n",
    "pred_gbr = gbr.predict(X_val)\n",
    "pred_ridge = ridge.predict(X_val)\n",
    "\n",
    "# Weighted average ensemble (weights can be tuned later)\n",
    "pred_ens = 0.2 * pred_rf + 0.6 * pred_gbr + 0.2 * pred_ridge\n",
    "\n",
    "rmse_log = np.sqrt(mean_squared_error(y_val, pred_ens))\n",
    "print(\"Ensemble Validation RMSE (log space):\", rmse_log)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "33f61170",
   "metadata": {},
   "source": [
    "## 9. Train Final Models and Generate Submission\n",
    "\n",
    "We retrain each model on the full training data (log space), generate predictions for the test set,\n",
    "invert the log transform, and save a file in the expected submission format.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "5a4bc11a",
   "metadata": {},
   "source": [
    "rf.fit(X, y_log)\n",
    "gbr.fit(X, y_log)\n",
    "ridge.fit(X, y_log)\n",
    "\n",
    "test_pred_log = (\n",
    "    0.2 * rf.predict(housing_test) +\n",
    "    0.6 * gbr.predict(housing_test) +\n",
    "    0.2 * ridge.predict(housing_test)\n",
    ")\n",
    "\n",
    "predictions = np.expm1(test_pred_log)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8aba3116",
   "metadata": {},
   "source": [
    "## 10. Conclusion and Next Steps\n",
    "\n",
    "This notebook demonstrates an end-to-end regression workflow:\n",
    "- EDA and missing value analysis\n",
    "- Feature engineering\n",
    "- Leakage-safe preprocessing with `Pipeline` + `ColumnTransformer`\n",
    "- Model training and validation\n",
    "- Simple weighted ensembling\n",
    "\n",
    "Potential next steps:\n",
    "- Use K-Fold cross-validation for more stable evaluation and fold-averaged predictions\n",
    "- Try specialized gradient boosting libraries (LightGBM / XGBoost / CatBoost)\n",
    "- Tune ensemble weights using cross-validation\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
